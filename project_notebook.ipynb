{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Birkbeck/bsc-computer-science-project-2021_22-mohammadreza490/blob/main/project_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''\n",
        "\n",
        "1. Convert stems to wav. https://pypi.org/project/musdb/ \n",
        "2. For each song, split into 2 second segments. Add padding as needed\n",
        "1. For each segment, create spectogram of whole mix of each song in training set via STFT\n",
        "2. Create array containing spectograms of bass of each song in training set\n",
        "3. Create array containing spectograms of (whole mix - bass) of each song in training set, see https://stackoverflow.com/questions/4039158/mixing-two-audio-files-together-with-python\n",
        "4. Add padding to arrays such that shape is appropriate for the network.\n",
        "4. Create CNN model\n",
        "5. Train model\n",
        "6. Apply inverse STFT / Get signal from the spectogram, see https://stackoverflow.com/questions/60377585/how-can-i-reverse-a-scipy-signal-spectrogram-to-audio-with-python\n",
        "                                                        https://stackoverflow.com/questions/76447360/how-do-i-can-reconstructing-stft-to-audio\n",
        "                                                        https://stackoverflow.com/questions/69387104/how-to-convert-wav-audio-file-from-mel-spectrogram\n",
        "7. Test model with a bunch of songs\n",
        "\n",
        "https://medium.com/@shameerayaseen21/u-net-advancing-image-segmentation-with-convolutional-neural-networks-1fd810f05d00\n",
        "'''\n",
        "\n",
        "'''\n",
        "TODO\n",
        "test data handling -> need space for this\n",
        "createCallbacks -> list of callbacks\n",
        "generateDataset -> from generator\n",
        "loadPretrained -> need path to models, so need to pass model name only\n",
        "predictSong -> need to pass song path only, return 2 wavs\n",
        "validateData -> validate using .npy test data (need test data handling)\n",
        "convertToWav -> usee ffmpeg probably\n",
        "resampleSong -> use ffmpeg \n",
        "ffmpeg \"Radiohead - Paranoid Android.wav\" -ar 44100 \"Radiohead - Paranoid Android (44100Hz).wav\"\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "PATH_TO_SRC_FOLDER = r\".\\src\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install musdb\n",
        "!pip install numpy\n",
        "!pip install pydub\n",
        "!pip install \"tensorflow<2.11\" #!pip install tensorflow==2.14\n",
        "# !pip install tensorflow-addons==0.22.0\n",
        "!pip install ipdb\n",
        "!pip install museval\n",
        "!pip install librosa\n",
        "!pip install matplotlib\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "sSOeC37OnHXK"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "import numpy as np\n",
        "import librosa\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import IPython.display as ipd\n",
        "import musdb\n",
        "import pydub\n",
        "import scipy\n",
        "import soundfile as sf\n",
        "import museval\n",
        "import random\n",
        "import math\n",
        "\n",
        "from scipy.io.wavfile import write\n",
        "from glob import glob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(tf.reduce_sum(tf.random.normal([1000, 1000])))\n",
        "\n",
        "print(tf.config.list_physical_devices('GPU'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "if PATH_TO_SRC_FOLDER not in sys.path:\n",
        "  sys.path.append(PATH_TO_SRC_FOLDER) # https://stackoverflow.com/questions/48905127/importing-py-files-in-google-colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "from wav_handler import WavHandler\n",
        "from dataset_handler import DatasetHandler\n",
        "from plotter import Plotter\n",
        "from model_builder import ModelBuilder\n",
        "from config import INPUT_WIDTH, INPUT_HEIGHT, INPUT_CHANNELS, OUTPUT_CHANNELS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "plotter = Plotter()\n",
        "model_builder = ModelBuilder()\n",
        "dataset_handler = DatasetHandler()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "unet = model_builder.buildModel()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# dataset_handler.writeTrainInputSpec()\n",
        "# dataset_handler.writeTrainOutputSpec()\n",
        "# dataset_handler.createBassless()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if not os.path.exists(\"./model/\"):\n",
        "    os.mkdir(\"./model\")\n",
        "\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint('./model/bass_separator_25e.h5', verbose=1, save_best_only=False, save_freq=\"epoch\")\n",
        "\n",
        "callbacks = [\n",
        "        tf.keras.callbacks.EarlyStopping(patience=5, monitor='loss'), \n",
        "        tf.keras.callbacks.TensorBoard(log_dir='logs'),\n",
        "        checkpoint]\n",
        "\n",
        "train_dataset =  tf.data.Dataset.from_generator(dataset_handler.dataGenerator,\n",
        "                                                       output_signature=(tf.TensorSpec(shape=(None, INPUT_WIDTH, INPUT_HEIGHT, INPUT_CHANNELS), dtype=tf.float64),\n",
        "                                                                   tf.TensorSpec(shape=(None, INPUT_WIDTH, INPUT_HEIGHT, OUTPUT_CHANNELS), dtype=tf.float64)))\n",
        "\n",
        "results = unet.fit(train_dataset, batch_size=dataset_handler.batch_size, epochs=25, callbacks=callbacks, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sample = WavHandler(wav=\"Thundercat - Dragonball Durag (44100Hz).wav\")\n",
        "segmented = sample.segmentWav()\n",
        "spectrograms = sample.computeSTFT(segmented)\n",
        "padded = sample.zeroPadSTFT(spectrograms)\n",
        "\n",
        "# istft = sample.computeInverseSTFT(padded)\n",
        "\n",
        "print(padded.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pretrained = tf.keras.models.load_model('./model/bass_separator_25e.h5')\n",
        "\n",
        "output = pretrained.predict(padded, batch_size=8, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(output.shape) # (x, 1040, 176, 2)\n",
        "\n",
        "# Changes the shape\n",
        "swap_axes = np.swapaxes(output, 0, -1)\n",
        "swap_axes = np.swapaxes(swap_axes, 1, 2)\n",
        "swap_axes = np.swapaxes(swap_axes, 1, -1)\n",
        "\n",
        "print(swap_axes.shape) # (2, x, 1040, 176)\n",
        "\n",
        "bass = swap_axes[0]\n",
        "bassless = swap_axes[1]\n",
        "\n",
        "print(bass.shape)\n",
        "print(bassless.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [],
      "source": [
        "bass_istft = sample.computeInverseSTFT(bass)\n",
        "bassless_istft = sample.computeInverseSTFT(bassless)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [],
      "source": [
        "bass_wav = bass_istft.wav\n",
        "bassless_wav = bassless_istft.wav\n",
        "sr = bass_istft.sr\n",
        "\n",
        "write(\"dball_bass.wav\", rate=sr, data=bass_wav)\n",
        "write(\"dball_bassless.wav\", rate=sr, data=bassless_wav)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyNepMn5SYw1L0XtDlq2nrH3",
      "include_colab_link": true,
      "name": "project_notebook.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
