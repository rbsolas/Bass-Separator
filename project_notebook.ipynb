{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Birkbeck/bsc-computer-science-project-2021_22-mohammadreza490/blob/main/project_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Bass Extractor - Project Notebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''\n",
        "\n",
        "1. Convert stems to wav. https://pypi.org/project/musdb/ \n",
        "2. For each song, split into 2 second segments. Add padding as needed\n",
        "1. For each segment, create spectogram of whole mix of each song in training set via STFT\n",
        "2. Create array containing spectograms of bass of each song in training set\n",
        "3. Create array containing spectograms of (whole mix - bass) of each song in training set, see https://stackoverflow.com/questions/4039158/mixing-two-audio-files-together-with-python\n",
        "4. Add padding to arrays such that shape is appropriate for the network.\n",
        "4. Create CNN model\n",
        "5. Train model\n",
        "6. Apply inverse STFT / Get signal from the spectogram, see https://stackoverflow.com/questions/60377585/how-can-i-reverse-a-scipy-signal-spectrogram-to-audio-with-python\n",
        "                                                        https://stackoverflow.com/questions/76447360/how-do-i-can-reconstructing-stft-to-audio\n",
        "                                                        https://stackoverflow.com/questions/69387104/how-to-convert-wav-audio-file-from-mel-spectrogram\n",
        "7. Test model with a bunch of songs\n",
        "\n",
        "https://medium.com/@shameerayaseen21/u-net-advancing-image-segmentation-with-convolutional-neural-networks-1fd810f05d00\n",
        "'''\n",
        "\n",
        "'''\n",
        "TODO\n",
        "test data handling -> need space for this\n",
        "createCallbacks -> list of callbacks\n",
        "generateDataset -> from generator\n",
        "loadPretrained -> need path to models, so need to pass model name only\n",
        "predictSong -> need to pass song path only, return 2 wavs\n",
        "validateData -> validate using .npy test data (need test data handling)\n",
        "convertToWav -> use ffmpeg probably\n",
        "resampleSong -> use ffmpeg \n",
        "ffmpeg -i \"Radiohead - Paranoid Android.wav\" -ar 44100 \"Radiohead - Paranoid Android (44100Hz).wav\"\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Installing and Importing Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Relative path to src folder here\n",
        "PATH_TO_SRC_FOLDER = r\".\\src\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ],
      "source": [
        "# Allows auto reloading of modules\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install dependencies\n",
        "!pip install musdb\n",
        "!pip install numpy\n",
        "!pip install pydub\n",
        "!pip install \"tensorflow<2.11\" # GPU can only be used for versions 2.10 and earlier\n",
        "!pip install ipdb\n",
        "!pip install museval\n",
        "!pip install librosa\n",
        "!pip install matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "sSOeC37OnHXK"
      },
      "outputs": [],
      "source": [
        "# Import modules\n",
        "import os\n",
        "import sys\n",
        "\n",
        "import numpy as np\n",
        "import librosa\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import IPython.display as ipd\n",
        "import musdb\n",
        "import pydub\n",
        "import scipy\n",
        "import soundfile as sf\n",
        "import museval\n",
        "import random\n",
        "import math\n",
        "\n",
        "from scipy.io.wavfile import write\n",
        "from glob import glob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Add path to src folder to the path variable \n",
        "if PATH_TO_SRC_FOLDER not in sys.path:\n",
        "  sys.path.append(PATH_TO_SRC_FOLDER) # https://stackoverflow.com/questions/48905127/importing-py-files-in-google-colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import user-defined modules\n",
        "from wav_handler import WavHandler\n",
        "from dataset_handler import DatasetHandler\n",
        "from plotter import Plotter\n",
        "from model_handler import ModelHandler\n",
        "from config import INPUT_WIDTH, INPUT_HEIGHT, INPUT_CHANNELS, OUTPUT_CHANNELS, PATH_TO_MODEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(-102.35193, shape=(), dtype=float32)\n",
            "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ]
        }
      ],
      "source": [
        "# Check if TensorFlow is properly installed and if GPU is detected\n",
        "print(tf.reduce_sum(tf.random.normal([1000, 1000])))\n",
        "print(tf.config.list_physical_devices('GPU'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Building the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "plotter = Plotter()\n",
        "model_handler = ModelHandler()\n",
        "dataset_handler = DatasetHandler()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "unet = model_handler.buildModel()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Preparing the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# dataset_handler.writeTrainInputSpec()\n",
        "# dataset_handler.writeTrainOutputSpec()\n",
        "# dataset_handler.createBassless()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "callbacks = model_handler.createCallbacks()\n",
        "train_dataset =  model_handler.buildDataFromGenerator()\n",
        "\n",
        "results = model_handler.modelFit(unet, callbacks, train_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Validating the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sampling rate:  44100\n",
            "Number of segments:  120\n",
            "Spectrograms shape:  (120, 1025, 173)\n",
            "Padded spectrograms shape:  (120, 1040, 176)\n",
            "\n",
            "15/15 [==============================] - 2s 92ms/step\n",
            "Output shape:  (120, 1040, 176, 2)\n",
            "Output shape (swapped axes):  (2, 120, 1040, 176)\n",
            "Bass output shape:  (120, 1040, 176)\n",
            "Bassless output shape:  (120, 1040, 176)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "song_path = \"c:/Users/Rohan/Music/9mm Parabellum Bullet - Heart Ni Hi Wo Tsukete (Dawning Version) (44100Hz).wav\"\n",
        "model_name = \"bass_separator_25e.h5\"\n",
        "\n",
        "bass, bassless = model_handler.predictSong(song_path, model_name)\n",
        "\n",
        "list = song_path.split(\"/\")\n",
        "song_name = list[-1][:-4]\n",
        "\n",
        "bass_istft, bassless_istft = model_handler.getOutputWavs(song_path, bass, bassless)\n",
        "\n",
        "model_handler.saveOutputs(bass_istft, bassless_istft, song_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sample = WavHandler(wav=\"Thundercat - Dragonball Durag (44100Hz).wav\")\n",
        "segmented = sample.segmentWav()\n",
        "spectrograms = sample.computeSTFT(segmented)\n",
        "padded = sample.zeroPadSTFT(spectrograms)\n",
        "\n",
        "# istft = sample.computeInverseSTFT(padded)\n",
        "\n",
        "print(padded.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pretrained = tf.keras.models.load_model('./model/bass_separator_25e.h5')\n",
        "\n",
        "output = pretrained.predict(padded, batch_size=8, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(output.shape) # (x, 1040, 176, 2)\n",
        "\n",
        "# Changes the shape\n",
        "swap_axes = np.swapaxes(output, 0, -1)\n",
        "swap_axes = np.swapaxes(swap_axes, 1, 2)\n",
        "swap_axes = np.swapaxes(swap_axes, 1, -1)\n",
        "\n",
        "print(swap_axes.shape) # (2, x, 1040, 176)\n",
        "\n",
        "bass = swap_axes[0]\n",
        "bassless = swap_axes[1]\n",
        "\n",
        "print(bass.shape)\n",
        "print(bassless.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [],
      "source": [
        "bass_istft = sample.computeInverseSTFT(bass)\n",
        "bassless_istft = sample.computeInverseSTFT(bassless)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [],
      "source": [
        "bass_wav = bass_istft.wav\n",
        "bassless_wav = bassless_istft.wav\n",
        "sr = bass_istft.sr\n",
        "\n",
        "write(\"dball_bass.wav\", rate=sr, data=bass_wav)\n",
        "write(\"dball_bassless.wav\", rate=sr, data=bassless_wav)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyNepMn5SYw1L0XtDlq2nrH3",
      "include_colab_link": true,
      "name": "project_notebook.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
